{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a Keras trained model using Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Set up\n",
    "\n",
    "After create a new notebook instance, set the kernel to conda_tensorflow_p36.\n",
    "\n",
    "The get_execution_role function retrieves the AWS Identity and Access Management (IAM) role you created at the time of creating your notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Load the Keras model using the json and weights file\n",
    "\n",
    "If you saved your model in the TensorFlow ProtoBuf format, skip to \"Step 4. Convert the TensorFlow model to an Amazon SageMaker-readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the model have json configuration file and weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('/home/ec2-user/SageMaker/model.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "model.load_weights('/home/ec2-user/SageMaker/model.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if model export by model.save (combine config and weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/home/ec2-user/SageMaker/model.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Export the Keras model to the TensorFlow ProtoBuf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes for the next section\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version\n",
    "\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": model.input}, outputs={\"score\": model.output})\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Convert TensorFlow model to a SageMaker readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tar the entire directory and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)\n",
    "    \n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Deploy the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!touch train.py\n",
    "\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "sagemaker_model = Model(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "                        role = role,\n",
    "                        framework_version='1.15.2',\n",
    "                        entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy step takes a long time, after that, sagemaker model and endpoint will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge', endpoint_name='endpoint-name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Invoke the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the SageMaker endpoint from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "predictor = sagemaker.tensorflow.model.TensorFlowPredictor(endpoint_name, sagemaker_session)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1, 160, 160)\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the SageMaker endpoint using a boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    " \n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "data = np.random.randn(1, 160, 160, 3).tolist()\n",
    "\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name, Body=json.dumps(data), ContentType='application/json')\n",
    "\n",
    "response_body = response['Body'].read()\n",
    "\n",
    "data = json.loads(response_body)['predictions']\n",
    "\n",
    "value = np.argmax(data)\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Clean up\n",
    "\n",
    "To avoid incurring unnecessary charges, use the AWS Management Console to delete the resources that you created for this exercise:\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
