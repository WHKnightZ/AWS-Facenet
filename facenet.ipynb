{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ảnh ra json: danh sách các vector của ảnh train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image, margin):\n",
    "    '''\n",
    "    sử dụng detectMultiScale của opencv để detect ra tọa độ các khuôn mặt từ ảnh image\n",
    "    :return: danh sách các khuôn mặt\n",
    "    '''\n",
    "    cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "#     faces = cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=3)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    aligned_images = []\n",
    "    margin_half = margin // 2\n",
    "    \n",
    "    for face in faces:\n",
    "        (x, y, w, h) = face\n",
    "        cropped = image[y - margin_half:y + h + margin_half, x - margin_half:x + w + margin_half,:]\n",
    "        aligned = cv2.resize(cropped, (160, 160))\n",
    "        aligned_images.append(aligned)\n",
    "\n",
    "    return faces, np.array(aligned_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    '''\n",
    "    tiền xử lý khuôn mặt trước khi đưa vào mô hình\n",
    "    '''\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0 / np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    '''\n",
    "    chuẩn hóa vector đầu ra\n",
    "    '''\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(image, margin=10):\n",
    "    '''\n",
    "    xử lý ảnh, đưa ảnh về vector \n",
    "    '''\n",
    "    faces, aligned_images = detect_faces(image, margin)\n",
    "    if len(faces) == 0:\n",
    "        return None, None\n",
    "\n",
    "    prewhiten_images = prewhiten(aligned_images)\n",
    "\n",
    "    predicts = model.predict_on_batch(prewhiten_images)\n",
    "\n",
    "    embs = []\n",
    "    for predict in predicts:\n",
    "        embs.append(l2_normalize(predict).tolist())\n",
    "\n",
    "    return faces, embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_distance(vector1, vector2):\n",
    "    '''\n",
    "    tính khoảng cách giữa 2 vector\n",
    "    '''\n",
    "    return distance.euclidean(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy toàn bộ thư mục trong Train, mỗi thư mục là một nhãn\n",
    "# trong mỗi thư mục chứa danh sách các ảnh cần train\n",
    "train_names = listdir('Train')\n",
    "\n",
    "data = []\n",
    "\n",
    "for name in train_names:\n",
    "    arr = []\n",
    "    path = join('Train', name)\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for file in files:\n",
    "        filepath = join(path, file)\n",
    "\n",
    "        # đọc ảnh xong tính vector đầu ra, đưa vào danh sách\n",
    "        image = cv2.imread(filepath)\n",
    "        _, embs = calc_embs(image)\n",
    "\n",
    "        # khi train thì mỗi ảnh chỉ có một khuôn mặt nên chỉ lấy phần từ đầu trong ds (embs[0])\n",
    "        arr.append(embs[0])\n",
    "\n",
    "    # mỗi khuôn mặt sẽ bao gồm nhãn (tên) và danh sách các vector đi kèm\n",
    "    data.append({'name': name, 'values': arr})\n",
    "\n",
    "data = {'data': data}\n",
    "\n",
    "with open('data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint(image, box, label):\n",
    "    '''\n",
    "    vẽ khung và thêm nhãn cho bức ảnh theo box và label\n",
    "    '''\n",
    "    color_box = [0, 192, 0] # màu xanh làm màu khung\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    x, y, w, h = box\n",
    "    text_width = cv2.getTextSize(label, font, 1.2, 2)[0][0]\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), color_box, 2)\n",
    "    cv2.putText(image, label, (x + 10, y + 25), font, 1.2, (255, 255, 255), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    '''\n",
    "    dự đoán tên người trong bức ảnh được truyền vào\n",
    "    '''\n",
    "    # trước tiên mở file data.json để lấy dữ liệu đã train: các khuôn mặt kèm theo các vector\n",
    "    with open('data.json') as json_file:\n",
    "        data = json.load(json_file)['data']\n",
    "\n",
    "    # lấy ra tất cả các box của ảnh\n",
    "    boxes, embs = calc_embs(image)\n",
    "    \n",
    "    if boxes is None:\n",
    "        return None\n",
    "\n",
    "    result = []\n",
    "    for box, emb in zip(boxes, embs):\n",
    "        min_value = 99999\n",
    "        label = None\n",
    "\n",
    "        # quét toàn bộ vector đã lấy từ file json, xem vector nào gần với khuôn mặt này nhất\n",
    "        for vectors in data:  # vectors là danh sách các tên người kèm các vector\n",
    "            for vector in vectors['values']:  # mỗi tên lại có nhiều vector (khuôn mặt)\n",
    "                dis = cal_distance(vector, emb)\n",
    "                if dis < min_value:\n",
    "                    min_value = dis\n",
    "                    label = vectors['name']\n",
    "        paint(image, box, label)  # tìm được box và label rồi thì vẽ vào ảnh\n",
    "        result.append({'box': box.tolist(), 'label': label})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filename = 'Test/test5.jpg'\n",
    "\n",
    "image = cv2.imread(filename)\n",
    "\n",
    "print(predict(image))\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
